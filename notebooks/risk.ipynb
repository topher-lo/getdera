{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic modelling risk narratives in mutual fund prospectuses\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import tempfile\n",
    "import warnings\n",
    "\n",
    "from getdera import dera\n",
    "from gensim import corpora\n",
    "from gensim import models\n",
    "from tqdm import tqdm\n",
    "\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.layouts import column\n",
    "from bokeh.palettes import all_palettes\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.plotting import show\n",
    "from bokeh.models import HoverTool\n",
    "from bokeh.models import CustomJS\n",
    "from bokeh.models import ColumnDataSource\n",
    "from bokeh.models import Slider\n",
    "\n",
    "from getdera.scrapper import client\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load bokeh into Jupyter\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Download and install spacy pretrained model\n",
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data prep\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBAL VARIABLES\n",
    "\n",
    "DATASET = \"risk\"\n",
    "DIR = tempfile.gettempdir()\n",
    "START_DATE = \"01/01/2019\"  # From start of 2019\n",
    "END_DATE = \"30/12/2019\"  # To end of 2019\n",
    "SELECTED_SUB_FIELDS = [\n",
    "    'name',  # Name of registrant\n",
    "    'cityba',  # City of registrant's business address\n",
    "    'pdate',  # Prospectus date\n",
    "]  # Selected fields in the SUB table\n",
    "SELECTED_TXT_FIELDS = [\n",
    "    'adsh',  # Accession number\n",
    "    'tag',  # Standard taxonomy tag\n",
    "    'value',  # Text\n",
    "]\n",
    "PARTS_OF_SPEECH = [\n",
    "    'NOUN',\n",
    "    'VERB',\n",
    "    'ADJ',\n",
    "    'ADV'\n",
    "]\n",
    "\n",
    "DATA = {}  # Data dictionary\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")  # Pretrained NLP model\n",
    "PIPE_PARAMS = {'n_process': multiprocessing.cpu_count(), 'batch_size': 50}  # Spacy pipeline parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data from sec.gov\n",
    "\n",
    "with tempfile.TemporaryDirectory(dir=DIR) as tmpdir:\n",
    "    # Download data and save in tempdir\n",
    "    client.get_DERA(DATASET, tmpdir, START_DATE, END_DATE)\n",
    "    # Process SUB data in tempdir\n",
    "    sub_table = dera.process(tmpdir, DATASET, 'sub', START_DATE, END_DATE, dtype={'pdate': str})\n",
    "    sub_table = sub_table[SELECTED_SUB_FIELDS]\n",
    "    DATA['sub'] = sub_table\n",
    "    # Process TXT data in tempdir\n",
    "    txt_table = dera.process(tmpdir, DATASET, 'txt', START_DATE, END_DATE, dtype={'document': str, 'txtlen': int})\n",
    "    txt_table = txt_table[SELECTED_TXT_FIELDS]\n",
    "    DATA['txt'] = txt_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILTER tags RiskNarrativeTextBlock\n",
    "\n",
    "DATA['risk'] = DATA['txt'].query('tag == \"RiskNarrativeTextBlock\"').set_index('adsh')\n",
    "\n",
    "# LEFT OUTER JOIN sub data with risk_data by index (adsh)\n",
    "\n",
    "data = DATA['sub'].merge(DATA['risk'], on='adsh', how='left')\n",
    "\n",
    "# Convert pdate to datetime\n",
    "\n",
    "data['pdate'] = pd.to_datetime(data['pdate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Language Processing Pipeline\n",
    "\n",
    "texts = data['value'].fillna('N/A').tolist()\n",
    "docs = []\n",
    "for doc in tqdm(nlp.pipe(texts, disable=[\"ner\", \"parser\"], **PIPE_PARAMS), total=len(data)):\n",
    "    doc = [token.lemma_.lower() for token in doc if token.pos_ in PARTS_OF_SPEECH]\n",
    "    docs.append(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Topic Modelling and Visualisation\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBAL VARIABLES\n",
    "\n",
    "# Assume there are 6 types of risk profiles \n",
    "# https://www.citibank.com.hk/english/investment/pdf/IRPQ_ICPQ_Eng.pdf\n",
    "\n",
    "N_TOPICS = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "# Get dictionary and corpus\n",
    "\n",
    "def get_dictionary_corpus(docs, no_below=5, no_above=0.5):\n",
    "    dictionary = corpora.Dictionary(docs)  # Dictionary\n",
    "    dictionary.filter_extremes(no_below, no_above)  # Filter extremes in dictionary\n",
    "    corpus = [dictionary.doc2bow(doc) for doc in docs]  # Corpus\n",
    "    return dictionary, corpus\n",
    "\n",
    "\n",
    "# Get LDA model\n",
    "# Note: Must set minimum_probability to 0 in order to perform\n",
    "# dimensionality reduction downstream\n",
    "\n",
    "def get_lda_model(corpus, dictionary, num_topics=N_TOPICS):\n",
    "    lda = models.LdaMulticore(corpus,\n",
    "                              id2word=dictionary,\n",
    "                              num_topics=num_topics,\n",
    "                              minimum_probability=0)\n",
    "    return lda\n",
    "\n",
    "\n",
    "# Get LDA topics df\n",
    "\n",
    "def get_lda_topics_df(lda):\n",
    "    topics_dict = {}\n",
    "    for i, topic in lda.print_topics(-1):\n",
    "        topics_dict['topic {}'.format(i)] = topic.split('+')\n",
    "    return pd.DataFrame(topics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check number of unique tokens\n",
    "\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary and corpus\n",
    "\n",
    "dictionary, corpus = get_dictionary_corpus(docs)\n",
    "\n",
    "# LDA model\n",
    "\n",
    "lda = get_lda_model(corpus, dictionary)\n",
    "\n",
    "# LDA topics df\n",
    "\n",
    "get_lda_topics_df(lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refactor results from LDA into \n",
    "# numpy matrix (number of prospectuses by number of topics)\n",
    "\n",
    "results = np.array([[vec for (j, vec) in lda[corpus[i]]] for i in range(len(corpus))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 PCA Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit PCA model\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "# Get embeddings\n",
    "\n",
    "embeddings_pca = pca.fit_transform(results)\n",
    "embeddings_pca = pd.DataFrame(embeddings_pca, columns=['x', 'y'])\n",
    "embeddings_pca['hue'] = results.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bokeh plot\n",
    "\n",
    "# Bokeh data source\n",
    "\n",
    "source = ColumnDataSource(data={\n",
    "    'x': embeddings_pca.x,\n",
    "    'y': embeddings_pca.y,\n",
    "    'colors': [all_palettes['Spectral'][11][i] for i in embeddings_pca.hue],\n",
    "    'name': data['name'],\n",
    "    'city': data['cityba'],\n",
    "    'pdate': data['pdate'],\n",
    "    'alpha': [0.5]*embeddings_pca.shape[0],\n",
    "    'size': [15]*embeddings_pca.shape[0]})\n",
    "\n",
    "# Plot\n",
    "\n",
    "title = 'Topic modelling risk narratives (LDA with PCA dimensionality reduction)'\n",
    "pca_plot = figure(plot_width=800,\n",
    "                  plot_height=800,\n",
    "                  tools=['hover', 'pan', 'wheel_zoom', 'reset'],\n",
    "                  title=title)\n",
    "pca_plot.circle('x', 'y',\n",
    "                size='size',  # Size according to 'colors' attribute in source\n",
    "                fill_color='colors',  # Color according to 'colors' attribute in source\n",
    "                alpha='alpha',  # Alpha according to 'colors' attribute in source\n",
    "                line_alpha=0,\n",
    "                line_width=0.01,\n",
    "                source=source)\n",
    "\n",
    "# Hover tool\n",
    "\n",
    "hover = pca_plot.select(dict(type=HoverTool))\n",
    "hover.tooltips = [('index', '$index'),\n",
    "                  ('name', '@name'),\n",
    "                  ('city', '@city'),\n",
    "                  ('prospectus date', '@pdate{%F}')]\n",
    "hover.formatters = {'@pdate': 'datetime'}\n",
    "\n",
    "show(pca_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 t-SNE Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit t-SNE model\n",
    "\n",
    "tsne = TSNE(random_state=0, init='pca', perplexity=30)\n",
    "\n",
    "# Get embeddings\n",
    "\n",
    "embeddings_tsne = tsne.fit_transform(results)\n",
    "embeddings_tsne = pd.DataFrame(embeddings_tsne, columns=['x','y'])\n",
    "embeddings_tsne['hue'] = results.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Bokeh plot\n",
    "\n",
    "# Bokeh data source\n",
    "\n",
    "source = ColumnDataSource(data={\n",
    "    'x': embeddings_tsne.x,\n",
    "    'y': embeddings_tsne.y,\n",
    "    'colors': [all_palettes['Spectral'][11][i] for i in embeddings_tsne.hue],\n",
    "    'name': data['name'],\n",
    "    'city': data['cityba'],\n",
    "    'pdate': data['pdate'],\n",
    "    'alpha': [0.5]*embeddings_tsne.shape[0],\n",
    "    'size': [15]*embeddings_tsne.shape[0]})\n",
    "\n",
    "# Plot\n",
    "\n",
    "title = 'Topic modelling risk narratives (LDA with t-SNE dimensionality reduction)'\n",
    "tsne_plot = figure(plot_width=800,\n",
    "                   plot_height=800,\n",
    "                   tools=[hover_tool, 'pan', 'wheel_zoom', 'reset'],\n",
    "                   title=title)\n",
    "tsne_plot.circle('x', 'y',\n",
    "                 size='size',  # Size according to 'colors' attribute in source\n",
    "                 fill_color='colors',  # Color according to 'colors' attribute in source\n",
    "                 alpha='alpha',  # Alpha according to 'colors' attribute in source\n",
    "                 line_alpha=0,\n",
    "                 line_width=0,\n",
    "                 source=source)\n",
    "\n",
    "# Hover tool\n",
    "\n",
    "hover = pca_plot.select(dict(type=HoverTool))\n",
    "hover.tooltips = [('index', '$index'),\n",
    "                  ('name', '@name'),\n",
    "                  ('city', '@city'),\n",
    "                  ('prospectus date', '@pdate{%F}')]\n",
    "hover.formatters = {'@pdate': 'datetime'}\n",
    "\n",
    "show(tsne_plot)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
